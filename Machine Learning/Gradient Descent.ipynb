{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bdb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "import random\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c310b1",
   "metadata": {},
   "source": [
    "<code>Gradient Descent For 2 Columns</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b85499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('./Data/simple_linear_regression_data.csv')\n",
    "X = df.iloc[:, 1].values.reshape(-1, 1)\n",
    "y = df.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc51c454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.691339362005465e+87 -8.19343792344914e+86\n"
     ]
    }
   ],
   "source": [
    "class GDRegressor():\n",
    "  def __init__(self,learning_score,epochs):\n",
    "    self.m=0\n",
    "    self.b=0\n",
    "    self.lr=learning_score\n",
    "    self.epochs=epochs\n",
    "  def fit(self,X_train,y_train):\n",
    "    for i in range(self.epochs):\n",
    "      loss_slope_b = -2 * np.sum(y_train - self.m*X_train.ravel() - self.b)\n",
    "      loss_slope_m = -2 * np.sum((y_train - self.m*X_train.ravel() - self.b)*X_train.ravel())\n",
    "      self.b = self.b -(self.lr*loss_slope_b)\n",
    "      self.m = self.m -(self.lr*loss_slope_m)\n",
    "    print(self.m,self.b)\n",
    "  def predict(self,X_test):\n",
    "    return self.m*X_test + self.b\n",
    "  \n",
    "gd = GDRegressor(0.01,50)\n",
    "gd.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e3e736d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2448591851218348"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gd.predict(X_test)\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30891b7e",
   "metadata": {},
   "source": [
    "<code>Gradient Descent For n Columns or batch GD</code>\n",
    "<pre>This GD update the parameter using entire data in each step\n",
    "This is good for small data</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0658cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X,y = load_diabetes(return_X_y=True)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c2d6c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  62.27835432  -24.14017912  262.40285385  192.20751489   39.48809013\n",
      "   10.26886323 -142.50597903  124.33312557  244.33510843  119.34350233] 151.94042847773682\n"
     ]
    }
   ],
   "source": [
    "class GDRegressor():\n",
    "  def __init__(self,learning_score,epochs):\n",
    "    self.coef_ = None\n",
    "    self.intercept_ = None\n",
    "    self.lr = learning_score\n",
    "    self.epochs = epochs\n",
    "\n",
    "  def fit(self,X_train,y_train):\n",
    "    self.intercept_ = 0\n",
    "    self.coef_ = np.ones(X_train.shape[1])\n",
    "\n",
    "    for i in range(self.epochs):\n",
    "      y_hat = self.intercept_ + np.dot(X_train,self.coef_)\n",
    "      intercept_der = -2 * np.mean(y_train - y_hat)\n",
    "      self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "\n",
    "      coef_der = -2 * np.dot((y_train - y_hat),X_train)/X_train.shape[0]\n",
    "      self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "\n",
    "    print(self.coef_,self.intercept_)\n",
    "  \n",
    "  def predict(self,X_test):\n",
    "    return np.dot(X_test,self.coef_) + self.intercept_\n",
    "  \n",
    "\n",
    "\n",
    "gd = GDRegressor(0.1,1000)\n",
    "gd.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8caaa9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=gd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a4da39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3971698388048742"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06681f27",
   "metadata": {},
   "source": [
    "<code>Stochastic GD</code>\n",
    "<pre>SGD update the parameter using single row in each step\n",
    "This is good for large data\n",
    "This is faster then BGS because it take less epochs to reach the answer</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba84f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4fb4366",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRegressor():\n",
    "  def __init__(self,learning_rate=0.1,epochs=100):\n",
    "    self.lr = learning_rate\n",
    "    self.epochs = epochs\n",
    "    self.coef_ = None\n",
    "    self.intercept_ =None\n",
    "  \n",
    "  def fit(self,X_train,y_train):\n",
    "\n",
    "    self.intercept_= 0\n",
    "    self.coef_ = np.ones(X_train.shape[1])\n",
    "\n",
    "\n",
    "    for i in range(self.epochs):\n",
    "      for j in range(X_train.shape[0]):\n",
    "        idx = random.randint(0,X_train.shape[0]-1)\n",
    "\n",
    "        y_hat = np.dot(X_train[idx],self.coef_) + self.intercept_\n",
    "        intercept_der = -2 * (y_train[idx] - y_hat)\n",
    "        self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "\n",
    "        coef_der = -2 * np.dot((y_train[idx] - y_hat),X_train[idx])\n",
    "        self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "    print(self.coef_,self.intercept_)\n",
    "  \n",
    "  def predict(self,X_test):\n",
    "    return np.dot(X_test,self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5b73842b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  33.5974029  -143.90626968  445.87387804  294.51197549  -45.89083794\n",
      " -116.55133006 -192.95520664  105.30980621  412.73236318   98.77398122] 151.02138082689302\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDRegressor(0.1,10)\n",
    "sgd.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "924a0179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45340073594010377"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sgd.predict(X_test)\n",
    "r2_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da658c54",
   "metadata": {},
   "source": [
    "<code>Mini-Batch GD</code>\n",
    "<pre>MBGD update the parameter using small small batch\n",
    "ex: row = 1000 , batch_size = 10 , per epochs 100 row\n",
    "This is good for large data\n",
    "This is faster then BGS because it take less epochs to reach the answer</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c0c4cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBGDRegressor():\n",
    "  def __init__(self,batch_size,learning_rate=0.1,epochs=100):\n",
    "    self.lr = learning_rate\n",
    "    self.epochs = epochs\n",
    "    self.coef_ = None\n",
    "    self.intercept_ =None\n",
    "    self.batch_size = batch_size\n",
    "  \n",
    "  def fit(self,X_train,y_train):\n",
    "\n",
    "    self.intercept_= 0\n",
    "    self.coef_ = np.ones(X_train.shape[1])\n",
    "\n",
    "\n",
    "    for i in range(self.epochs):\n",
    "      for j in range(int(X_train.shape[0]/self.batch_size)):\n",
    "        idx = random.sample(range(X_train.shape[0]),self.batch_size)\n",
    "\n",
    "        y_hat = np.dot(X_train[idx],self.coef_) + self.intercept_\n",
    "        intercept_der = -2 * np.mean((y_train[idx] - y_hat))\n",
    "        self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "\n",
    "        coef_der = -2 * np.dot((y_train[idx] - y_hat),X_train[idx])\n",
    "        self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "    print(self.coef_,self.intercept_)\n",
    "  \n",
    "  def predict(self,X_test):\n",
    "    return np.dot(X_test,self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7fa7328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  40.61127011 -131.03298936  443.32755175  302.8758411   -11.66176732\n",
      "  -94.22755413 -175.83314242  108.65025447  426.18234941  136.40990018] 146.7646415129892\n"
     ]
    }
   ],
   "source": [
    "mrb = MBGDRegressor(batch_size=int(X_train.shape[0]/10),learning_rate=0.1,epochs=10)\n",
    "mrb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0662609d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44093834168519574"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mrb.predict(X_test)\n",
    "r2_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
